{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "noVZx5Y3Bzgr",
    "outputId": "0b2b10ae-0c35-4c8d-c1de-1e16b479df30"
   },
   "outputs": [],
   "source": [
    "# === üì¶ Imports ===\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFRobertaForSequenceClassification, RobertaTokenizer\n",
    "!pip install lime\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib  # for loading XGBoost model\n",
    "from keras.models import load_model  # for LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === üìÅ Load all models from Google Drive ===\n",
    "bert_path = \"/content/drive/My Drive/tf_bert_sentiment_model\"\n",
    "roberta_path = \"/content/drive/My Drive/roberta_sentiment_model_final\"\n",
    "lstm_path = \"/content/drive/My Drive/Sentimental-Analysis/models/lstm_model.h5\"\n",
    "xgb_path = \"/content/drive/My Drive/Sentimental-Analysis/models/xgb_model.pkl\"\n",
    "vectorizer_path = \"/content/drive/My Drive/Sentimental-Analysis/models/tfidf_vectorizer.pkl\"\n",
    "\n",
    "# === üì• Load Tokenizers & Models ===\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_path, local_files_only=True)\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(bert_path, local_files_only=True)\n",
    "\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(roberta_path, local_files_only=True)\n",
    "roberta_model = TFRobertaForSequenceClassification.from_pretrained(roberta_path, local_files_only=True)\n",
    "\n",
    "lstm_model = load_model(lstm_path)\n",
    "xgb_model = joblib.load(xgb_path)\n",
    "vectorizer = joblib.load(vectorizer_path)\n",
    "\n",
    "# === üè∑Ô∏è Labels ===\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.array(['negative', 'neutral', 'positive'])\n",
    "class_names = list(label_encoder.classes_)\n",
    "\n",
    "# === üîç Individual Model Prediction Functions ===\n",
    "def bert_predict(texts):\n",
    "    inputs = bert_tokenizer(texts, return_tensors=\"tf\", padding=True, truncation=True, max_length=128)\n",
    "    outputs = bert_model(inputs)\n",
    "    return tf.nn.softmax(outputs.logits, axis=-1).numpy()\n",
    "\n",
    "def roberta_predict(texts):\n",
    "    inputs = roberta_tokenizer(texts, return_tensors=\"tf\", padding=True, truncation=True, max_length=128)\n",
    "    outputs = roberta_model(inputs)\n",
    "    return tf.nn.softmax(outputs.logits, axis=-1).numpy()\n",
    "\n",
    "def lstm_predict(texts):\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    tokenizer_lstm = Tokenizer(num_words=5000)\n",
    "    tokenizer_lstm.fit_on_texts(texts)\n",
    "    sequences = tokenizer_lstm.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=100)\n",
    "    probs = lstm_model.predict(padded)\n",
    "    return probs\n",
    "\n",
    "def xgb_predict(texts):\n",
    "    X = vectorizer.transform(texts)\n",
    "    probs = xgb_model.predict_proba(X)\n",
    "    return probs\n",
    "\n",
    "# === ü§ù Ensemble Prediction Function ===\n",
    "def ensemble_predict_proba(texts):\n",
    "    bert_probs = bert_predict(texts)\n",
    "    roberta_probs = roberta_predict(texts)\n",
    "    lstm_probs = lstm_predict(texts)\n",
    "    xgb_probs = xgb_predict(texts)\n",
    "    ensemble_probs = (bert_probs + roberta_probs + lstm_probs + xgb_probs) / 4.0\n",
    "    return ensemble_probs\n",
    "\n",
    "# === üìä Plotting Function for Class Probabilities ===\n",
    "def plot_probabilities(probabilities, classes):\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    bars = plt.bar(classes, probabilities, alpha=0.7)\n",
    "    plt.ylim(0, 1)\n",
    "    for bar, prob in zip(bars, probabilities):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, prob + 0.02, f'{prob:.2f}', ha='center', fontsize=10)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.title(\"Predicted Class Probabilities\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# === üß† LIME Setup ===\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# === üìù Sample Tweets for Explanation ===\n",
    "sample_tweets = [\n",
    "    \"The flight was delayed and customer service was terrible\",\n",
    "    \"I love the new seats and the food was excellent!\",\n",
    "    \"The check-in process was okay, nothing special.\",\n",
    "    \"Worst experience ever. I will never fly with them again.\",\n",
    "    \"Very smooth journey and friendly crew members.\"\n",
    "]\n",
    "\n",
    "# === üîç Loop Through Tweets and Explain with LIME ===\n",
    "for i, tweet in enumerate(sample_tweets, 1):\n",
    "    print(f\"\\n{'='*40}\\nüìù Example {i}\\nTweet: {tweet}\")\n",
    "    proba = ensemble_predict_proba([tweet])[0]\n",
    "    predicted_label = label_encoder.classes_[np.argmax(proba)]\n",
    "\n",
    "    print(f\"‚úÖ Predicted Sentiment (Ensemble): {predicted_label}\")\n",
    "    print(f\"üî¢ Class Probabilities: {dict(zip(class_names, proba.round(3)))}\")\n",
    "\n",
    "    # üìä Plot the bar chart\n",
    "    plot_probabilities(proba, class_names)\n",
    "\n",
    "    # üß† Show LIME explanation\n",
    "    exp = explainer.explain_instance(tweet, ensemble_predict_proba, num_features=6, top_labels=1)\n",
    "    exp.show_in_notebook(text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420,
     "referenced_widgets": [
      "13147afb49ff4ab4936906af6cf37eb6",
      "c7c0af9ee14c4752a75ba3d465a47c9c",
      "5df93648864d4fc1b5fc14bf8962ebd1",
      "c19724c339f2491289ab24ba2c7fb257",
      "58ac6e5e78d3422fb8b22b03b7942349",
      "789e71fa9f624b58a457feab12397d21",
      "b9c57fe7da1146f781c486ba4d00c102",
      "9a2caf88ab1740d09bebb1e5a8738f78",
      "a1dde96a28d94d188f01d9c935dda365",
      "53b0648168134c56bfc6702cd7e4c204",
      "4f45539aaaa341bbb14521ea817c1363",
      "629982e318684ef0beddf6cf5fee7183",
      "5a31627ea2cf4565987fe670f451de28",
      "d7f1797ec75445f798f3835aa0753704",
      "7762ef3e11754214b23da860cf04f907",
      "e17befc286c04b45bbbbd53e1971e306",
      "c759954100284a8d9062d5a814352f6e",
      "ebcfde7726a44db3bb4cb72d121b8e5e",
      "1d38d4770138444ea87ae900d8bb89f5",
      "2303d15b4a5e4bdbae67f7e79dc3e4c3",
      "d2a1ab4fa76a4016ae313398433022ab",
      "aac8586e99ef4e4099bcb13813750012",
      "ec1b846a96554d718dc1ed8ae7dde1fc",
      "a576c0a9a21643c6af19709e53e9fe06",
      "12a3e631a78d4583b297652e71e41628",
      "6e0bf0ed757a476a9ecc98cf7c0ada57",
      "98474d5ce28c48eea4919830c99bca8c",
      "cf24339e90864974ad9091eb65c5a8d3",
      "9466cf821b8342af809636c667de7f82",
      "9214e396c92c4d99b545b4d1dc113b55",
      "b8b89ab41405433fa9e333380d2fd1f9",
      "f75ea0e1e6594a4c8eaff0f56a54ba62",
      "38cb99e7a09f4a21b92d00a70fd61b9b",
      "3ede0e96a582438ba0f8421d3c02ce76",
      "eed5292358494746926038cf7bce01c1",
      "932a4496961a4e56bcbbff8f06d11959",
      "94e988c147704b6282d3b6d6f6a9ea9e",
      "d8569c013cfa46968bee19e1a9467a03",
      "1c390a47d8d246e993462b0b9b7b4595",
      "82190c06475045ac812bab940c8b82fe",
      "5fe1f6358d4146a7a5a601d796d0a87a",
      "8aa3faa59d5e4a299d1a5d490a0c8827",
      "9a4081643e4249e7a9df69c6e958b5e5",
      "22ea2faafdb14c64aa555dd51f843080",
      "5c0efb7ba0b3400a81cac678bb95bc9d",
      "89c353d9fb3144c88ef230da56db4790",
      "5a505f449577435abbd3291a60e54ad6",
      "0ec68650ad804977b9e965c5dfa8eb7c",
      "9b7b8164df354facb23e8741c5e8b085",
      "28a4cc9182cc4d5180897b3aa04713cf",
      "79329b7e33124616b4fae59baadf345d",
      "f5f3ffe309234bafb5f40a0235f4a86c",
      "af4879bb31e444ad9108dadd172578ec",
      "f7cfb4e355f144e88a4cdceda17b0b11",
      "8eb53e2f78714172acec11a7430cb095",
      "86ddc0ea1dd24ee0a50fadd0511c2122",
      "1308319d210c4e0f841625f2888fe9db",
      "7cb61ae02f4e474093528d188e52ed5d",
      "766a96a4e0f940f88ff345ef95fa4822",
      "e7709f2c680746608fb571633161ae8e",
      "7034b705df4f4868812e7d6bcacaa895",
      "5f8361e1258540838a6a7dd2758f9e5b",
      "87222304287440a8928863945105b692",
      "5aa667c98a584e4a8ac4ff0bb4d9b591",
      "7daf3867effc4134bec0d41dee960a28",
      "1362fcd3bc054e559032462a3e1e4ef0"
     ]
    },
    "id": "RbFeoNc69ZwP",
    "outputId": "4f6e2472-700f-4dce-885c-9382879bfd3c"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "\n",
    "save_path = \"/content/drive/My Drive/roberta_sentiment_model_final\"\n",
    "\n",
    "# Load pretrained RoBERTa\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta_model = TFRobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3)\n",
    "\n",
    "# Save to Drive\n",
    "roberta_tokenizer.save_pretrained(save_path)\n",
    "roberta_model.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xa0Lh3Ne7kW_",
    "outputId": "9e72dfae-8c21-4e48-f01c-afc4f5da456d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
