{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ad93db6228e4d4d84aba6fb33bae9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1890b255cd8a44ed8037f8ef476fe2f7",
              "IPY_MODEL_f1133d2ba50b44ce9b8e73a2f4b99d1f",
              "IPY_MODEL_25ae24e573e84de593afa8715a81c08d"
            ],
            "layout": "IPY_MODEL_aa28af06ec054e95ba498bb7aa2d0a08"
          }
        },
        "1890b255cd8a44ed8037f8ef476fe2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d8fb79486a243cf82842d0b6841ea4f",
            "placeholder": "​",
            "style": "IPY_MODEL_acfefa63c24b4c2c872cf6aab3ffad63",
            "value": "model.safetensors:  87%"
          }
        },
        "f1133d2ba50b44ce9b8e73a2f4b99d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926d8ddaa9da475398628c18a0a012bb",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be92ecd4134d4685adc06b517089fc46",
            "value": 431814515
          }
        },
        "25ae24e573e84de593afa8715a81c08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e57089ce14604f418a757f0e78c9e50a",
            "placeholder": "​",
            "style": "IPY_MODEL_b879733bc9c444cdbeccee743088c307",
            "value": " 432M/499M [00:04&lt;00:00, 112MB/s]"
          }
        },
        "aa28af06ec054e95ba498bb7aa2d0a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8fb79486a243cf82842d0b6841ea4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acfefa63c24b4c2c872cf6aab3ffad63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "926d8ddaa9da475398628c18a0a012bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be92ecd4134d4685adc06b517089fc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e57089ce14604f418a757f0e78c9e50a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b879733bc9c444cdbeccee743088c307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasaniselviGanesan/Sentimental-Analysis/blob/main/cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6ad93db6228e4d4d84aba6fb33bae9c5",
            "1890b255cd8a44ed8037f8ef476fe2f7",
            "f1133d2ba50b44ce9b8e73a2f4b99d1f",
            "25ae24e573e84de593afa8715a81c08d",
            "aa28af06ec054e95ba498bb7aa2d0a08",
            "6d8fb79486a243cf82842d0b6841ea4f",
            "acfefa63c24b4c2c872cf6aab3ffad63",
            "926d8ddaa9da475398628c18a0a012bb",
            "be92ecd4134d4685adc06b517089fc46",
            "e57089ce14604f418a757f0e78c9e50a",
            "b879733bc9c444cdbeccee743088c307"
          ]
        },
        "id": "1H919Wh7yUyY",
        "outputId": "5a4623ae-32ae-4791-8bfd-4833a76505c0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ad93db6228e4d4d84aba6fb33bae9c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 183/183 [03:06<00:00,  1.02s/it]\n",
            "100%|██████████| 46/46 [00:44<00:00,  1.03it/s]\n",
            "100%|██████████| 183/183 [02:57<00:00,  1.03it/s]\n",
            "100%|██████████| 46/46 [00:44<00:00,  1.04it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [16:41:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 Accuracy: 0.8255\n",
            "\n",
            "--- Fold 2 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 183/183 [03:02<00:00,  1.00it/s]\n",
            "100%|██████████| 46/46 [00:44<00:00,  1.03it/s]\n",
            "100%|██████████| 183/183 [02:55<00:00,  1.04it/s]\n",
            "100%|██████████| 46/46 [00:44<00:00,  1.02it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [16:50:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 2 Accuracy: 0.8142\n",
            "\n",
            "--- Fold 3 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 183/183 [02:57<00:00,  1.03it/s]\n",
            "100%|██████████| 46/46 [00:44<00:00,  1.03it/s]\n",
            "100%|██████████| 183/183 [03:00<00:00,  1.01it/s]\n",
            "100%|██████████| 46/46 [00:45<00:00,  1.02it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [16:59:00] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 3 Accuracy: 0.8084\n",
            "\n",
            "--- Fold 4 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 183/183 [02:59<00:00,  1.02it/s]\n",
            "100%|██████████| 46/46 [00:44<00:00,  1.03it/s]\n",
            "100%|██████████| 183/183 [02:57<00:00,  1.03it/s]\n",
            "100%|██████████| 46/46 [00:45<00:00,  1.02it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [17:07:54] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 4 Accuracy: 0.8156\n",
            "\n",
            "--- Fold 5 ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 183/183 [03:00<00:00,  1.02it/s]\n",
            "100%|██████████| 46/46 [00:45<00:00,  1.01it/s]\n",
            "100%|██████████| 183/183 [02:59<00:00,  1.02it/s]\n",
            "100%|██████████| 46/46 [00:45<00:00,  1.02it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [17:16:49] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Accuracy: 0.8245\n",
            "\n",
            "✅ Average Accuracy over 5 folds: 0.8176\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import BertTokenizer, TFBertModel, RobertaTokenizer, TFRobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Sentimental-Analysis/data/Tweets.csv')\n",
        "df = df[['text', 'airline_sentiment']]\n",
        "df = df.dropna()\n",
        "\n",
        "# Label encoding\n",
        "df['label'] = df['airline_sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})\n",
        "\n",
        "# Clean text (basic)\n",
        "def clean_text(text):\n",
        "    text = tf.strings.regex_replace(text, '[^a-zA-Z ]', '').numpy().decode('utf-8')\n",
        "    return text.lower()\n",
        "\n",
        "df['clean_text'] = df['text'].map(lambda x: clean_text(tf.convert_to_tensor(x)))\n",
        "\n",
        "# Tokenizer for LSTM\n",
        "tokenizer_lstm = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "tokenizer_lstm.fit_on_texts(df['clean_text'])\n",
        "max_len = 50\n",
        "\n",
        "def get_lstm_embeddings(texts):\n",
        "    sequences = tokenizer_lstm.texts_to_sequences(texts)\n",
        "    padded = pad_sequences(sequences, maxlen=max_len)\n",
        "    return padded\n",
        "\n",
        "# Load BERT & RoBERTa\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Batching to avoid OOM\n",
        "def get_transformer_embeddings(texts, tokenizer, model, batch_size=64):\n",
        "    embeddings = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size)):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        tokens = tokenizer(batch, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "        output = model(tokens)[0]  # (batch_size, seq_len, hidden_size)\n",
        "        cls_embeddings = tf.reduce_mean(output, axis=1).numpy()\n",
        "        embeddings.extend(cls_embeddings)\n",
        "        tf.keras.backend.clear_session(); gc.collect()\n",
        "    return np.array(embeddings)\n",
        "\n",
        "# LSTM model\n",
        "def create_lstm_model():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=10000, output_dim=64, input_length=max_len),\n",
        "        LSTM(64),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 5-Fold Cross-Validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "acc_scores = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(df['clean_text'], df['label'])):\n",
        "    print(f\"\\n--- Fold {fold+1} ---\")\n",
        "\n",
        "    X_train_text = df['clean_text'].iloc[train_idx].tolist()\n",
        "    X_test_text = df['clean_text'].iloc[test_idx].tolist()\n",
        "    y_train = df['label'].iloc[train_idx].values\n",
        "    y_test = df['label'].iloc[test_idx].values\n",
        "\n",
        "    # LSTM Embedding & Model\n",
        "    X_train_lstm = get_lstm_embeddings(X_train_text)\n",
        "    X_test_lstm = get_lstm_embeddings(X_test_text)\n",
        "    lstm_model = create_lstm_model()\n",
        "    lstm_model.fit(X_train_lstm, y_train, epochs=2, batch_size=64, verbose=0)\n",
        "    lstm_preds = np.argmax(lstm_model.predict(X_test_lstm), axis=1)\n",
        "\n",
        "    # BERT embeddings\n",
        "    X_train_bert = get_transformer_embeddings(X_train_text, bert_tokenizer, bert_model)\n",
        "    X_test_bert = get_transformer_embeddings(X_test_text, bert_tokenizer, bert_model)\n",
        "\n",
        "    # RoBERTa embeddings\n",
        "    X_train_roberta = get_transformer_embeddings(X_train_text, roberta_tokenizer, roberta_model)\n",
        "    X_test_roberta = get_transformer_embeddings(X_test_text, roberta_tokenizer, roberta_model)\n",
        "\n",
        "    # XGBoost on combined features\n",
        "    X_train_combined = np.concatenate([X_train_lstm, X_train_bert, X_train_roberta], axis=1)\n",
        "    X_test_combined = np.concatenate([X_test_lstm, X_test_bert, X_test_roberta], axis=1)\n",
        "\n",
        "    xgb = XGBClassifier(n_estimators=100, max_depth=4, use_label_encoder=False, eval_metric='mlogloss')\n",
        "    xgb.fit(X_train_combined, y_train)\n",
        "    xgb_preds = xgb.predict(X_test_combined)\n",
        "\n",
        "    acc = accuracy_score(y_test, xgb_preds)\n",
        "    acc_scores.append(acc)\n",
        "    print(f\"Fold {fold+1} Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(f\"\\n✅ Average Accuracy over 5 folds: {np.mean(acc_scores):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufcRgiJhx07F",
        "outputId": "bdedf86b-8ccb-495d-faee-66a3c3bf1553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}